listPhoneDictTiming = shows computational time when using a list of tuples from word to pronunciation

mapPhoneDictTiming = shows comp time when using a HashMap instead

multPhone = shows increase in no. of passed tests when supporting multiple pronunciations for a word

usingARPABETtype = switching from representing arpabet with strings to its own data type to implement arrays. 
                  Initialisation of dict is noticably slower (~5 secs -> ~40 secs)

fuzzy1 = Threshold: 5. 
         Number of tests passing incresed from 412 -> 429 out of 577
         Many exceptions of "Exception: Prelude.minimum: empty list" which indicates word is not in dictionary
         Many failed tests are words where it is expected to pronounce individual letters like "is"
            (pronouncing "i" and "s" seperately can be similar to "eyes")
         Possible to add extra test cases where given words like "he will", the program converts it to "he'll" 

fuzzy2 = Seperated tests that do not pass because they don't exist in dictionary. 431/480 homophoneTable passed
         Code has not changed from fuzzy1 
         Most failed test cases are either words not in the dictionary or words that have R which is silent in British

usingStrNFuzzy = Using String dict instead for faster dict loading time. Only convert to Arpabet after lookupArpabet
                 Significantly faster (30s -> 4s)
                 Same tests as Fuzzy2. No extra tests should be passing but it increased from 431 to 436 (possible overlook)

convertToBRitish = Omits R sounds at the end of syllables. Also edited R to ER score mapping (100 -> 3)
                   Passing tests increased from 436 -> 467

TODO:
- Add false positives in tests to finetune fuzzy search
- Remove Rs for British accent
- add more accent features
- multiple words support for homophones rev dict function
- spoonerisms, rhyming, etc.
- Matches words not in dictionary? Or partially not in dictionary (past tense, letter pronunciations)
- stats for homophones (proportion of homophone)
- east london (TH -> F)
- Construct diff ways of pronouncing words (dialect and stuff)
- "EYOT"/"AIT" similar spelling to "buoy"
- generate fuzzy hom change 2 letters then backtrack

former spoken on the radio
 |      |
 past   oral   = pastoral
 ["P","AE","S","T"] + ["AO","R","AH","L"] = ["P","AE","S","T","ER","AH","L"]

 splitNopt = split into multiple words

 ["past","oral"] and ["pastoral"] = true

 homophone of charades is a charade of homophones


 ghci> homophone ["in","close"] ["enclose"]
    True


["anele"] ["an","eel"] -- anele not in dict

["key","naps"] ["kneecaps"] -- spoonerisms. convert to arpabet then swap
remunerator, re numerator -- spoonerisms. quote for future works
["tidied"] ["tie","deed"] -- fuzzy homophone. tidied doesn't exist in dict

think abt usage of this other than crossword:
- speech recognition, especially from non native speakers with accents so fuzzy homophone
   can catch it.


given [[...,high,tall,..],[jack,...]] we could filter stuff that obviously is not a homophone of hijack
   to save computational time but we sacrifice this for simpler code.


rev dictionary is to construct data for testing (especially fuzzy homophone)

mention in report that:
we can construct specific tables for specific accents.
we take a semantic approach compared to using Neural Network (dtaa already available)
"conger" and "conga" should not be a homophone despite being in homophoneTable (same with "pascal" n "paschal")